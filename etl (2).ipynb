{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sql_queries import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "#cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "#conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "#cur = conn.cursor()\n",
    "\n",
    " # connect to default database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "    \n",
    "    # create sparkify database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS sparkifydb1\")\n",
    "cur.execute(\"CREATE DATABASE sparkifydb1 WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "    # close connection to default database\n",
    "conn.close()    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb1 user=student password=student\")\n",
    "cur = conn.cursor()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        \n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `song_data`\n",
    "In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "Let's perform ETL on a single song file and load a single record into each table to start.\n",
    "- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n",
    "- Select the first song in this list\n",
    "- Read the song file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_files = get_files('data/song_data/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = song_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist_id  artist_latitude  artist_location  artist_longitude  \\\n",
      "0  ARD7TVE1187B99BFB1              NaN  California - LA               NaN   \n",
      "\n",
      "  artist_name   duration  num_songs             song_id             title  \\\n",
      "0      Casual  218.93179          1  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
      "\n",
      "   year  \n",
      "0     0  \n"
     ]
    }
   ],
   "source": [
    "#Read JSON file through PANDAS function read_json\n",
    "data = pd.read_json(filepath,lines=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #1: `songs` Table\n",
    "#### Extract Data for Songs Table\n",
    "- Select columns for song ID, title, artist ID, year, and duration\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `song_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist_id  artist_latitude  artist_location  artist_longitude  \\\n",
      "0  ARD7TVE1187B99BFB1              NaN  California - LA               NaN   \n",
      "\n",
      "  artist_name   duration  num_songs             song_id             title  \\\n",
      "0      Casual  218.93179          1  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
      "\n",
      "   year  \n",
      "0     0  \n"
     ]
    }
   ],
   "source": [
    "#Convert data to a Data Frame for easy execution & print values\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Record into Song Table\n",
    "Implement the `song_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song into the `songs` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songs` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOMZWCG12A8C13C480', \"I Didn't Mean To\", 'ARD7TVE1187B99BFB1', 0, 218.93179)\n",
      "            artist_id  artist_latitude  artist_location  artist_longitude  \\\n",
      "0  ARD7TVE1187B99BFB1              NaN  California - LA               NaN   \n",
      "\n",
      "  artist_name   duration  num_songs             song_id             title  \\\n",
      "0      Casual  218.93179          1  SOMZWCG12A8C13C480  I Didn't Mean To   \n",
      "\n",
      "   year  \n",
      "0     0  \n"
     ]
    }
   ],
   "source": [
    "#For test purposes only, CREATE table\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS songs3(songplay_id varchar, title varchar, artist_id varchar, year int, duration float)\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "#Insert dataframe data using function ITERTUPLES() in a for loop\n",
    "try:\n",
    "     for row in df.itertuples():\n",
    "         cur.execute(\"INSERT INTO songs3(songplay_id, title, artist_id, year, duration)\\\n",
    "                      VALUES (%s,%s,%s,%s,%s)\",\\\n",
    "                      (row.song_id,\n",
    "                       row.title,\n",
    "                       row.artist_id,\n",
    "                       row.year,\n",
    "                       row.duration)\n",
    "                   ) \n",
    "\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: INsert error\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "#Check if values have been correctly inserted & print them out\n",
    "cur.execute(\"SELECT * FROM songs3;\")\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #2: `artists` Table\n",
    "#### Extract Data for Artists Table\n",
    "- Select columns for artist ID, name, location, latitude, and longitude\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `artist_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARD7TVE1187B99BFB1', 'Casual', 'California - LA', nan, nan)\n"
     ]
    }
   ],
   "source": [
    "#For test purposes only, CREATE table\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS artists(artist_id varchar,name text, location varchar,latitude float, longitude float)\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "#Insert dataframe data using function ITERTUPLES() in a for loop\n",
    "try:\n",
    "     for row in df.itertuples():\n",
    "         cur.execute(\"INSERT INTO artists(artist_id,name,location,latitude,longitude)\\\n",
    "                      VALUES (%s,%s,%s,%s,%s)\",\\\n",
    "                      (row.artist_id,\n",
    "                       row.artist_name,\n",
    "                       row.artist_location,\n",
    "                       row.artist_latitude,\n",
    "                       row.artist_longitude)\n",
    "                   ) \n",
    "\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: INsert error\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "#Check if values have been correctly inserted & print them out\n",
    "cur.execute(\"SELECT * FROM artists;\")\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Record into Artist Table\n",
    "Implement the `artist_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song's artist into the `artists` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `artists` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process `log_data`\n",
    "In this part, you'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "Let's perform ETL on a single log file and load a single record into each table.\n",
    "- Use the `get_files` function provided above to get a list of all log JSON files in `data/log_data`\n",
    "- Select the first log file in this list\n",
    "- Read the log file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Get all the files from the log folder\n",
    "log_files = get_files('data/log_data/2018/11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Pick up the first file in the log folder\n",
    "filepath = log_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      artist        auth firstName gender  \\\n",
      "0                              Stephen Lynch   Logged In    Jayden      M   \n",
      "1                                    Manowar   Logged In     Jacob      M   \n",
      "2                                  Morcheeba   Logged In     Jacob      M   \n",
      "3                                   Maroon 5   Logged In     Jacob      M   \n",
      "4                                      Train   Logged In     Jacob      M   \n",
      "5                                      LMFAO   Logged In     Jacob      M   \n",
      "6                                   DJ Dizzy   Logged In     Jacob      M   \n",
      "7                    Fish Go Deep & Tracey K   Logged In     Jacob      M   \n",
      "8                                       None   Logged In    Alivia      F   \n",
      "9                                        M83   Logged In     Jacob      M   \n",
      "10                                    Saybia   Logged In     Jacob      M   \n",
      "11                             Local Natives   Logged In     Jacob      M   \n",
      "12                                South Park   Logged In     Jacob      M   \n",
      "13                    UNKLE Feat. Josh Homme   Logged In     Jacob      M   \n",
      "14                       Justyna Steczkowska   Logged In     Jacob      M   \n",
      "15                               Evanescence   Logged In     Jacob      M   \n",
      "16                                  Coldplay   Logged In     Jacob      M   \n",
      "17                                  Hot Chip   Logged In     Jacob      M   \n",
      "18                            Ellie Goulding   Logged In     Jacob      M   \n",
      "19                            Postal Service   Logged In     Jacob      M   \n",
      "20                                      None   Logged In     Jacob      M   \n",
      "21                                      None  Logged Out      None   None   \n",
      "22                                      None   Logged In     Aiden      M   \n",
      "23                              Jack Johnson   Logged In     Aiden      M   \n",
      "24                             Iron And Wine   Logged In     Aiden      M   \n",
      "25                                    The xx   Logged In     Aiden      M   \n",
      "26                               The Antlers   Logged In     Aiden      M   \n",
      "27                                Fattburger   Logged In     Aiden      M   \n",
      "28                                      None   Logged In     Layla      F   \n",
      "29                                      None   Logged In     Layla      F   \n",
      "..                                       ...         ...       ...    ...   \n",
      "358                                Mr. Vegas   Logged In     Chloe      F   \n",
      "359                           Mischa Daniels   Logged In     Rylan      M   \n",
      "360                           The Menzingers   Logged In     Chloe      F   \n",
      "361                        Justin Timberlake   Logged In     Chloe      F   \n",
      "362                   Vilma Palma e Vampiros   Logged In     Rylan      M   \n",
      "363                 CCCP - Fedeli Alla Linea   Logged In     Chloe      F   \n",
      "364                Kid Cudi / MGMT / Ratatat   Logged In     Rylan      M   \n",
      "365  Drake / Kanye West / Lil Wayne / Eminem   Logged In     Chloe      F   \n",
      "366                        A Day To Remember   Logged In     Rylan      M   \n",
      "367                                     T.I.   Logged In    Jayden      M   \n",
      "368                            The Offspring   Logged In     Rylan      M   \n",
      "369                           Jorge Gonzalez   Logged In     Chloe      F   \n",
      "370                            Sneaker Pimps   Logged In    Jayden      M   \n",
      "371                          Escape The Fate   Logged In     Rylan      M   \n",
      "372                                   Juanes   Logged In     Chloe      F   \n",
      "373                         The Replacements   Logged In     Rylan      M   \n",
      "374                          Sarah McLachlan   Logged In     Chloe      F   \n",
      "375                     Sonny Boy Williamson   Logged In     Rylan      M   \n",
      "376     Soul II Soul Featuring Caron Wheeler   Logged In     Rylan      M   \n",
      "377                   Florence + The Machine   Logged In     Chloe      F   \n",
      "378                                  Pantera   Logged In     Rylan      M   \n",
      "379                                     None   Logged In     Rylan      M   \n",
      "380                                     Cold   Logged In     Chloe      F   \n",
      "381                                  Norther   Logged In     Chloe      F   \n",
      "382                             Foo Fighters   Logged In     Rylan      M   \n",
      "383                               Timbiriche   Logged In     Rylan      M   \n",
      "384                         A Perfect Circle   Logged In     Rylan      M   \n",
      "385                                 Anberlin   Logged In     Rylan      M   \n",
      "386                                     None   Logged In     Rylan      M   \n",
      "387                                Deas Vail   Logged In    Elijah      M   \n",
      "\n",
      "     itemInSession lastName     length level  \\\n",
      "0                0     Bell  182.85669  free   \n",
      "1                0    Klein  247.56200  paid   \n",
      "2                1    Klein  257.41016  paid   \n",
      "3                2    Klein  231.23546  paid   \n",
      "4                3    Klein  216.76363  paid   \n",
      "5                4    Klein  227.99628  paid   \n",
      "6                5    Klein  221.15220  paid   \n",
      "7                6    Klein  377.41669  paid   \n",
      "8                0  Terrell        NaN  free   \n",
      "9                7    Klein   96.18240  paid   \n",
      "10               8    Klein  257.25342  paid   \n",
      "11               9    Klein  266.05669  paid   \n",
      "12              10    Klein  112.97914  paid   \n",
      "13              11    Klein  307.19955  paid   \n",
      "14              12    Klein  333.53098  paid   \n",
      "15              13    Klein  256.91383  paid   \n",
      "16              14    Klein  297.35138  paid   \n",
      "17              15    Klein  333.50485  paid   \n",
      "18              16    Klein  205.06077  paid   \n",
      "19              17    Klein  307.53914  paid   \n",
      "20              18    Klein        NaN  paid   \n",
      "21              19     None        NaN  paid   \n",
      "22               0     Hess        NaN  free   \n",
      "23               1     Hess  240.06485  free   \n",
      "24               2     Hess  153.05098  free   \n",
      "25               3     Hess  158.24934  free   \n",
      "26               4     Hess  328.88118  free   \n",
      "27               5     Hess  217.20771  free   \n",
      "28               0  Griffin        NaN  paid   \n",
      "29               1  Griffin        NaN  paid   \n",
      "..             ...      ...        ...   ...   \n",
      "358             12   Cuevas  240.69179  paid   \n",
      "359             46   George  419.81342  paid   \n",
      "360             13   Cuevas  276.00934  paid   \n",
      "361             14   Cuevas  288.93995  paid   \n",
      "362             47   George  338.18077  paid   \n",
      "363             15   Cuevas  329.66485  paid   \n",
      "364             48   George  295.67955  paid   \n",
      "365             16   Cuevas  357.66812  paid   \n",
      "366             49   George  247.64036  paid   \n",
      "367              0     Bell  299.75465  free   \n",
      "368             50   George  163.31710  paid   \n",
      "369             17   Cuevas  272.14322  paid   \n",
      "370              1     Bell  260.91057  free   \n",
      "371             51   George  266.73587  paid   \n",
      "372             18   Cuevas  243.27791  paid   \n",
      "373             52   George  170.57914  paid   \n",
      "374             19   Cuevas  278.90893  paid   \n",
      "375             53   George  152.24118  paid   \n",
      "376             54   George  225.22730  paid   \n",
      "377             20   Cuevas  219.66322  paid   \n",
      "378             55   George  286.69342  paid   \n",
      "379             56   George        NaN  paid   \n",
      "380             21   Cuevas  177.76281  paid   \n",
      "381             22   Cuevas  246.54322  paid   \n",
      "382             57   George  271.38567  paid   \n",
      "383             58   George  202.60526  paid   \n",
      "384             59   George  206.05342  paid   \n",
      "385             60   George  348.68200  paid   \n",
      "386             61   George        NaN  paid   \n",
      "387              0    Davis  237.68771  free   \n",
      "\n",
      "                                location method       page  registration  \\\n",
      "0        Dallas-Fort Worth-Arlington, TX    PUT   NextSong  1.540992e+12   \n",
      "1    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "2    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "3    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "4    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "5    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "6    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "7    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "8                 Parkersburg-Vienna, WV    GET       Home  1.540505e+12   \n",
      "9    Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "10   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "11   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "12   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "13   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "14   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "15   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "16   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "17   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "18   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "19   Tampa-St. Petersburg-Clearwater, FL    PUT   NextSong  1.540558e+12   \n",
      "20   Tampa-St. Petersburg-Clearwater, FL    PUT     Logout  1.540558e+12   \n",
      "21                                  None    GET       Home           NaN   \n",
      "22             La Crosse-Onalaska, WI-MN    GET       Home  1.540829e+12   \n",
      "23             La Crosse-Onalaska, WI-MN    PUT   NextSong  1.540829e+12   \n",
      "24             La Crosse-Onalaska, WI-MN    PUT   NextSong  1.540829e+12   \n",
      "25             La Crosse-Onalaska, WI-MN    PUT   NextSong  1.540829e+12   \n",
      "26             La Crosse-Onalaska, WI-MN    PUT   NextSong  1.540829e+12   \n",
      "27             La Crosse-Onalaska, WI-MN    PUT   NextSong  1.540829e+12   \n",
      "28          Lake Havasu City-Kingman, AZ    GET       Home  1.541057e+12   \n",
      "29          Lake Havasu City-Kingman, AZ    GET   Settings  1.541057e+12   \n",
      "..                                   ...    ...        ...           ...   \n",
      "358    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "359                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "360    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "361    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "362                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "363    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "364                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "365    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "366                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "367      Dallas-Fort Worth-Arlington, TX    PUT   NextSong  1.540992e+12   \n",
      "368                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "369    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "370      Dallas-Fort Worth-Arlington, TX    PUT   NextSong  1.540992e+12   \n",
      "371                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "372    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "373                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "374    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "375                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "376                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "377    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "378                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "379                Birmingham-Hoover, AL    GET       Help  1.541020e+12   \n",
      "380    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "381    San Francisco-Oakland-Hayward, CA    PUT   NextSong  1.540941e+12   \n",
      "382                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "383                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "384                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "385                Birmingham-Hoover, AL    PUT   NextSong  1.541020e+12   \n",
      "386                Birmingham-Hoover, AL    GET  Downgrade  1.541020e+12   \n",
      "387          Detroit-Warren-Dearborn, MI    PUT   NextSong  1.540772e+12   \n",
      "\n",
      "     sessionId                                               song  status  \\\n",
      "0          829                                  Jim Henson's Dead     200   \n",
      "1         1049                                        Shell Shock     200   \n",
      "2         1049               Women Lose Weight (Feat: Slick Rick)     200   \n",
      "3         1049                          Won't Go Home Without You     200   \n",
      "4         1049                                   Hey_ Soul Sister     200   \n",
      "5         1049                                 I'm In Miami Bitch     200   \n",
      "6         1049                                         Sexy Bitch     200   \n",
      "7         1049         The Cure & The Cause (Dennis Ferrer Remix)     200   \n",
      "8         1070                                               None     200   \n",
      "9         1049                                      Staring At Me     200   \n",
      "10        1049                               The Second You Sleep     200   \n",
      "11        1049                                          Wide Eyes     200   \n",
      "12        1049                La Resistance (Medley) (LP Version)     200   \n",
      "13        1049                                           Restless     200   \n",
      "14        1049                                             Noc...     200   \n",
      "15        1049                                           Like You     200   \n",
      "16        1049                     God Put A Smile Upon Your Face     200   \n",
      "17        1049                                            Playboy     200   \n",
      "18        1049                                  Every Time You Go     200   \n",
      "19        1049                             Natural Anthem (Album)     200   \n",
      "20        1049                                               None     307   \n",
      "21        1049                                               None     200   \n",
      "22         986                                               None     200   \n",
      "23         986                                             Taylor     200   \n",
      "24         986                                    Naked As We Can     200   \n",
      "25         986                                            Fantasy     200   \n",
      "26         986                                           Epilogue     200   \n",
      "27         986                                           Groovin'     200   \n",
      "28        1051                                               None     200   \n",
      "29        1051                                               None     200   \n",
      "..         ...                                                ...     ...   \n",
      "358       1114                                             Tamale     200   \n",
      "359       1076                                      Another Place     200   \n",
      "360       1114                                   Straight To Hell     200   \n",
      "361       1114                                     Cry Me A River     200   \n",
      "362       1076                                Un Camino Hasta Vos     200   \n",
      "363       1114                       Sura (2008 Digital Remaster)     200   \n",
      "364       1076                   Pursuit Of Happiness (nightmare)     200   \n",
      "365       1114                                            Forever     200   \n",
      "366       1076                                Homesick [Acoustic]     200   \n",
      "367       1085  Dead And Gone [feat. Justin Timberlake] (Expli...     200   \n",
      "368       1076               It'll Be a Long Time (Album Version)     200   \n",
      "369       1114                      Esta Es Para Hacerte FÃÂ©liz     200   \n",
      "370       1085                                    Spin Spin Sugar     200   \n",
      "371       1076               This War Is Ours (The Guillotine II)     200   \n",
      "372       1114                               La Vida Es Un Ratico     200   \n",
      "373       1076                                         Never Mind     200   \n",
      "374       1114                                         Possession     200   \n",
      "375       1076                             Don't Start Me Talkin'     200   \n",
      "376       1076  Back To Life (However Do You Want Me) (2003 Di...     200   \n",
      "377       1114                     Dog Days Are Over (Radio Edit)     200   \n",
      "378       1076                               Heresy  (LP Version)     200   \n",
      "379       1076                                               None     200   \n",
      "380       1114                                             Remedy     200   \n",
      "381       1114                                       Frozen Angel     200   \n",
      "382       1076                                      The Pretender     200   \n",
      "383       1076                                    Besos De Ceniza     200   \n",
      "384       1076                                               Rose     200   \n",
      "385       1076                                       The Haunting     200   \n",
      "386       1076                                               None     200   \n",
      "387        985              Anything You Say (Unreleased Version)     200   \n",
      "\n",
      "                ts                                          userAgent userId  \n",
      "0    1543537327796  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...     91  \n",
      "1    1543540121796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "2    1543540368796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "3    1543540625796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "4    1543540856796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "5    1543541072796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "6    1543541299796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "7    1543541520796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "8    1543541644796  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      4  \n",
      "9    1543541897796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "10   1543541993796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "11   1543542250796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "12   1543542516796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "13   1543542628796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "14   1543542935796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "15   1543543268796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "16   1543543524796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "17   1543543821796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "18   1543544154796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "19   1543544359796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "20   1543544360796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     73  \n",
      "21   1543544407796                                               None         \n",
      "22   1543547152796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "23   1543547190796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "24   1543547430796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "25   1543547583796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "26   1543547741796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "27   1543548069796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     86  \n",
      "28   1543548391796  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...     24  \n",
      "29   1543548494796  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...     24  \n",
      "..             ...                                                ...    ...  \n",
      "358  1543600483796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "359  1543600644796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "360  1543600723796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "361  1543600999796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "362  1543601063796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "363  1543601287796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "364  1543601401796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "365  1543601616796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "366  1543601696796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "367  1543601780796  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...     91  \n",
      "368  1543601943796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "369  1543601973796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "370  1543602079796  Mozilla/5.0 (compatible; MSIE 10.0; Windows NT...     91  \n",
      "371  1543602106796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "372  1543602245796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "373  1543602372796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "374  1543602488796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "375  1543602542796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "376  1543602694796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "377  1543602766796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "378  1543602919796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "379  1543602936796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "380  1543602985796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "381  1543603162796  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...     49  \n",
      "382  1543603205796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "383  1543603476796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "384  1543603678796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "385  1543603884796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "386  1543603993796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     16  \n",
      "387  1543607664796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      5  \n",
      "\n",
      "[388 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "#Using PANDA functions, read through the contents of the first file and display that\n",
    "df_log = pd.read_json(filepath, lines=True)\n",
    "print(df_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #3: `time` Table\n",
    "#### Extract Data for Time Table\n",
    "- Filter records by `NextSong` action\n",
    "- Convert the `ts` timestamp column to datetime\n",
    "  - Hint: the current timestamp is in milliseconds\n",
    "- Extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a list containing these values in order\n",
    "  - Hint: use pandas' [`dt` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) to access easily datetimelike properties.\n",
    "- Specify labels for these columns and set to `column_labels`\n",
    "- Create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Filter records by NextSong action & store it in a variable df_filter\n",
    "df_filter = df_log[(df_log['page'] == 'NextSong')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2018-11-30 00:22:07.796\n",
      "1     2018-11-30 01:08:41.796\n",
      "2     2018-11-30 01:12:48.796\n",
      "3     2018-11-30 01:17:05.796\n",
      "4     2018-11-30 01:20:56.796\n",
      "5     2018-11-30 01:24:32.796\n",
      "6     2018-11-30 01:28:19.796\n",
      "7     2018-11-30 01:32:00.796\n",
      "9     2018-11-30 01:38:17.796\n",
      "10    2018-11-30 01:39:53.796\n",
      "11    2018-11-30 01:44:10.796\n",
      "12    2018-11-30 01:48:36.796\n",
      "13    2018-11-30 01:50:28.796\n",
      "14    2018-11-30 01:55:35.796\n",
      "15    2018-11-30 02:01:08.796\n",
      "16    2018-11-30 02:05:24.796\n",
      "17    2018-11-30 02:10:21.796\n",
      "18    2018-11-30 02:15:54.796\n",
      "19    2018-11-30 02:19:19.796\n",
      "23    2018-11-30 03:06:30.796\n",
      "24    2018-11-30 03:10:30.796\n",
      "25    2018-11-30 03:13:03.796\n",
      "26    2018-11-30 03:15:41.796\n",
      "27    2018-11-30 03:21:09.796\n",
      "30    2018-11-30 03:29:23.796\n",
      "31    2018-11-30 03:32:46.796\n",
      "33    2018-11-30 03:37:24.796\n",
      "35    2018-11-30 03:39:31.796\n",
      "36    2018-11-30 03:44:28.796\n",
      "38    2018-11-30 03:49:50.796\n",
      "                ...          \n",
      "356   2018-11-30 17:49:45.796\n",
      "357   2018-11-30 17:53:44.796\n",
      "358   2018-11-30 17:54:43.796\n",
      "359   2018-11-30 17:57:24.796\n",
      "360   2018-11-30 17:58:43.796\n",
      "361   2018-11-30 18:03:19.796\n",
      "362   2018-11-30 18:04:23.796\n",
      "363   2018-11-30 18:08:07.796\n",
      "364   2018-11-30 18:10:01.796\n",
      "365   2018-11-30 18:13:36.796\n",
      "366   2018-11-30 18:14:56.796\n",
      "367   2018-11-30 18:16:20.796\n",
      "368   2018-11-30 18:19:03.796\n",
      "369   2018-11-30 18:19:33.796\n",
      "370   2018-11-30 18:21:19.796\n",
      "371   2018-11-30 18:21:46.796\n",
      "372   2018-11-30 18:24:05.796\n",
      "373   2018-11-30 18:26:12.796\n",
      "374   2018-11-30 18:28:08.796\n",
      "375   2018-11-30 18:29:02.796\n",
      "376   2018-11-30 18:31:34.796\n",
      "377   2018-11-30 18:32:46.796\n",
      "378   2018-11-30 18:35:19.796\n",
      "380   2018-11-30 18:36:25.796\n",
      "381   2018-11-30 18:39:22.796\n",
      "382   2018-11-30 18:40:05.796\n",
      "383   2018-11-30 18:44:36.796\n",
      "384   2018-11-30 18:47:58.796\n",
      "385   2018-11-30 18:51:24.796\n",
      "387   2018-11-30 19:54:24.796\n",
      "Name: timestamp, Length: 330, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Convert data in ts column to date and time. Create another column timestamp and add that to the dataframe.    \n",
    "df_filter['timestamp'] = (pd.to_datetime(df_filter['ts'], unit='ms'))\n",
    "print(df_filter['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ts  hr  Day  WoY  mm    yy  weekday       start_time\n",
      "0 2018-11-30 00:22:07.796   0   30   48  11  2018        4  00:22:07.796000\n",
      "1 2018-11-30 01:08:41.796   1   30   48  11  2018        4  01:08:41.796000\n",
      "2 2018-11-30 01:12:48.796   1   30   48  11  2018        4  01:12:48.796000\n",
      "3 2018-11-30 01:17:05.796   1   30   48  11  2018        4  01:17:05.796000\n",
      "4 2018-11-30 01:20:56.796   1   30   48  11  2018        4  01:20:56.796000\n"
     ]
    }
   ],
   "source": [
    "#timedata = []\n",
    "\n",
    "#Convert timestamp column into multiple data frame columns\n",
    "#df_filter['YY']=df_filter.timestamp.dt.year()\n",
    "#print(df_filter['YY'])\n",
    "\n",
    "#Add Timestamp to a list\n",
    "#timedata = ((df_filter.ts.head()).tolist())\n",
    "\n",
    "#Add Year to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.year.head()).tolist())\n",
    "\n",
    "#Add Month to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.month.head()).tolist())\n",
    "\n",
    "\n",
    "#Add Day to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.day.head()).tolist())\n",
    "\n",
    "\n",
    "#Add Hour to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.hour.head()).tolist())\n",
    "\n",
    "\n",
    "#Add Week Of Year to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.week.head()).tolist())\n",
    "\n",
    "#Add Week Day to Timedata list\n",
    "#timedata.append((df_filter.timestamp.dt.weekday_name.head()).tolist())\n",
    "#print(timedata)\n",
    "\n",
    "#column_labels = []\n",
    "#column_lables = ['Timestamp','Year']\n",
    "#print(column_labels)\n",
    "\n",
    "#Extract individual row content from Data Frame and then append it a list\n",
    "\n",
    "time_data = [ df_filter[\"timestamp\"], df_filter[\"timestamp\"].dt.hour, df_filter[\"timestamp\"].dt.day, df_filter[\"timestamp\"].dt.weekofyear, df_filter[\"timestamp\"].dt.month, df_filter[\"timestamp\"].dt.year, df_filter[\"timestamp\"].dt.weekday,df_filter[\"timestamp\"].dt.time]\n",
    "#print(time_data)\n",
    "column_labels = ['ts','hr','Day','WoY','mm','yy','weekday','start_time']\n",
    "time_data_dict=dict(zip(column_labels,time_data))\n",
    "#print(time_data_dict)\n",
    "\n",
    "time_df=pd.DataFrame.from_dict(time_data_dict)\n",
    "print(time_df.head())\n",
    "#print(type(time_df['start_time']))\n",
    "#except psycopg2.Error as e: \n",
    "#    print(\"Error: INsert error\")\n",
    "#    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#time_df = pd.DataFrame(timedata,columns=column_labels)\n",
    "#print(time_df)\n",
    "#time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Time Table\n",
    "Implement the `time_table_insert` query in `sql_queries.py` and run the cell below to insert records for the timestamps in this log file into the `time` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `time` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#For test purposes only, CREATE table\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS time(start_time time, hour int, day int,week int, month int, year int, weekday int)\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "#Insert dataframe data using function ITERTUPLES() in a for loop\n",
    "try:\n",
    "     for row in time_df.itertuples():\n",
    "         cur.execute(\"INSERT INTO time(start_time,hour,day,week,month,year,weekday)\\\n",
    "                      VALUES (%s,%s,%s,%s,%s,%s,%s)\",\\\n",
    "                      (row.start_time,\n",
    "                       row.hr,\n",
    "                       row.Day,\n",
    "                       row.WoY,\n",
    "                       row.mm,\n",
    "                       row.yy,\n",
    "                       row.weekday)\n",
    "                   ) \n",
    "\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: INsert error\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "#Check if values have been correctly inserted & print them out\n",
    "#cur.execute(\"SELECT * FROM time;\")\n",
    "#row = cur.fetchone()\n",
    "#while row:\n",
    "#   print(row)\n",
    "#   row = cur.fetchone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #4: `users` Table\n",
    "#### Extract Data for Users Table\n",
    "- Select columns for user ID, first name, last name, gender and level and set to `user_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userId  firstName   lastName gender level\n",
      "0       91     Jayden       Bell      M  free\n",
      "1       73      Jacob      Klein      M  paid\n",
      "8        4     Alivia    Terrell      F  free\n",
      "22      86      Aiden       Hess      M  free\n",
      "28      24      Layla    Griffin      F  paid\n",
      "40      26       Ryan      Smith      M  free\n",
      "59      49      Chloe     Cuevas      F  paid\n",
      "62      57  Katherine        Gay      F  free\n",
      "67      30      Avery    Watkins      F  paid\n",
      "78      92      Ryann      Smith      F  free\n",
      "95      69   Anabelle    Simpson      F  free\n",
      "125     74     Braden     Parker      M  free\n",
      "134     88   Mohammad  Rodriguez      M  paid\n",
      "145     36    Matthew      Jones      M  paid\n",
      "168      8     Kaylee    Summers      F  free\n",
      "177     12     Austin    Rosales      M  free\n",
      "184     61     Samuel   Gonzalez      M  free\n",
      "194     43     Jahiem      Miles      M  free\n",
      "196     68     Jordan  Rodriguez      F  free\n",
      "204     85    Kinsley      Young      F  paid\n",
      "213     50        Ava   Robinson      F  free\n",
      "214      6    Cecilia      Owens      F  free\n",
      "239    101     Jayden        Fox      M  free\n",
      "243     16      Rylan     George      M  paid\n",
      "306     78      Chloe       Roth      F  free\n",
      "316     33    Bronson     Harris      M  free\n",
      "387      5     Elijah      Davis      M  free\n"
     ]
    }
   ],
   "source": [
    "#df_log contains user_id, f_name,l_name,gender,level. We need to transfer those values to the user data frame\n",
    "user_df1 = df_log[['userId','firstName','lastName','gender','level']].copy()\n",
    "user_df=user_df1.dropna()\n",
    "user_df=user_df.drop_duplicates()\n",
    "print(user_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Records into Users Table\n",
    "Implement the `user_table_insert` query in `sql_queries.py` and run the cell below to insert records for the users in this log file into the `users` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `users` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 'Jayden', 'Bell', 'M', 'free')\n",
      "(73, 'Jacob', 'Klein', 'M', 'paid')\n",
      "(4, 'Alivia', 'Terrell', 'F', 'free')\n",
      "(86, 'Aiden', 'Hess', 'M', 'free')\n",
      "(24, 'Layla', 'Griffin', 'F', 'paid')\n",
      "(26, 'Ryan', 'Smith', 'M', 'free')\n",
      "(49, 'Chloe', 'Cuevas', 'F', 'paid')\n",
      "(57, 'Katherine', 'Gay', 'F', 'free')\n",
      "(30, 'Avery', 'Watkins', 'F', 'paid')\n",
      "(92, 'Ryann', 'Smith', 'F', 'free')\n",
      "(69, 'Anabelle', 'Simpson', 'F', 'free')\n",
      "(74, 'Braden', 'Parker', 'M', 'free')\n",
      "(88, 'Mohammad', 'Rodriguez', 'M', 'paid')\n",
      "(36, 'Matthew', 'Jones', 'M', 'paid')\n",
      "(8, 'Kaylee', 'Summers', 'F', 'free')\n",
      "(12, 'Austin', 'Rosales', 'M', 'free')\n",
      "(61, 'Samuel', 'Gonzalez', 'M', 'free')\n",
      "(43, 'Jahiem', 'Miles', 'M', 'free')\n",
      "(68, 'Jordan', 'Rodriguez', 'F', 'free')\n",
      "(85, 'Kinsley', 'Young', 'F', 'paid')\n",
      "(50, 'Ava', 'Robinson', 'F', 'free')\n",
      "(6, 'Cecilia', 'Owens', 'F', 'free')\n",
      "(101, 'Jayden', 'Fox', 'M', 'free')\n",
      "(16, 'Rylan', 'George', 'M', 'paid')\n",
      "(78, 'Chloe', 'Roth', 'F', 'free')\n",
      "(33, 'Bronson', 'Harris', 'M', 'free')\n",
      "(5, 'Elijah', 'Davis', 'M', 'free')\n"
     ]
    }
   ],
   "source": [
    "#For test purposes only, CREATE table\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS users2(user_id int, fname text, lname text,gender text,level varchar)\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "'''for row in user_df.itertuples():\n",
    "    cur.execute(\"INSERT INTO users(user_id,fname,lname,gender,level)\\\n",
    "                 VALUES (%s,%s,%s,%s,%s)\",\\\n",
    "                 (row.userId,\n",
    "                  row.firstName,\n",
    "                  row.lastName,\n",
    "                  row.gender,\n",
    "                  row.level)\n",
    "               )\n",
    "          \n",
    "conn.commit()\n",
    "'''    \n",
    "try:\n",
    "     for row in user_df.itertuples():\n",
    "         cur.execute(\"INSERT INTO users2(user_id,fname,lname,gender,level)\\\n",
    "                      VALUES (%s,%s,%s,%s,%s)\",\\\n",
    "                      (row.userId,\n",
    "                      row.firstName,\n",
    "                      row.lastName,\n",
    "                      row.gender,\n",
    "                      row.level)\n",
    "                    ) \n",
    "\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: INsert error\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "#Check if values have been correctly inserted & print them out\n",
    "\n",
    "cur.execute(\"SELECT * FROM users2;\")\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## #5: `songplays` Table\n",
    "#### Extract Data and Songplays Table\n",
    "This one is a little more complicated since information from the songs table, artists table, and original log file are all needed for the `songplays` table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.\n",
    "- Implement the `song_select` query in `sql_queries.py` to find the song ID and artist ID based on the title, artist name, and duration of a song.\n",
    "- Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to `songplay_data`\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "- Implement the `songplay_table_insert` query and run the cell below to insert records for the songplay actions in this log file into the `songplays` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songplays` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-47ed2a9e12f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#get songid and artistid from song and artist tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_select\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#    results = cur.fetchone()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "#get songid and artistid from song and artist tables\n",
    "    cur.execute(song_select,(row.title, row.artist_name, row.duration))\n",
    "#    results = cur.fetchone()\n",
    "    print(cur.fetchone())   \n",
    "#    if results:\n",
    "#        songid, artistid = results\n",
    "#    else:\n",
    "#        songid, artistid = None, None\n",
    "\n",
    "# insert songplay record\n",
    "#    songplay_data = ()\n",
    "#    cur.execute(songplay_table_insert, songplay_data)\n",
    "#conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Close Connection to Sparkify Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Implement `etl.py`\n",
    "Use what you've completed in this notebook to implement `etl.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
